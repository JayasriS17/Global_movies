# prepare_data.py
"""
prepare_data.py
- Tries to download the Kaggle dataset "yasirabdaali/tmdb-20000-trending-movies-dataset"
  using the Kaggle CLI if credentials are available as environment variables or Streamlit secrets.
- Looks for CSV files in ./data/ after download and uses the first plausible CSV.
- Cleans columns to ensure: title, original_language, release_date, vote_average, vote_count
- Writes global_movies_clean.csv in project root.
- If download is not possible, generates a small sample CSV for testing.
"""
import os
import glob
import zipfile
import pandas as pd
import numpy as np
import subprocess
import shutil

DATA_DIR = "data"
OUTPUT_CSV = "global_movies_clean.csv"
KAGGLE_SLUG = "yasirabdaali/tmdb-20000-trending-movies-dataset"

def try_kaggle_download():
    """Attempt to download the dataset using kaggle CLI if available and credentials set."""
    try:
        # Ensure data directory exists
        os.makedirs(DATA_DIR, exist_ok=True)
        print("Attempting to download dataset via kaggle CLI...")
        # `kaggle datasets download -d <slug> -p data --unzip`
        cmd = ["kaggle", "datasets", "download", "-d", KAGGLE_SLUG, "-p", DATA_DIR, "--unzip"]
        proc = subprocess.run(cmd, check=False, capture_output=True, text=True)
        if proc.returncode != 0:
            print("Kaggle download failed or kaggle CLI not present. stdout/stderr:")
            print(proc.stdout)
            print(proc.stderr)
            return False
        print("Download successful.")
        return True
    except Exception as e:
        print("Exception while trying to download via kaggle:", e)
        return False

def find_csv_file():
    """Find a plausible CSV in the data directory."""
    csvs = glob.glob(os.path.join(DATA_DIR, "*.csv"))
    if not csvs:
        # also check root (in case user placed it there)
        csvs = glob.glob("*.csv")
    if not csvs:
        return None
    # Prefer files containing 'tmdb' or 'movies'
    for c in csvs:
        name = os.path.basename(c).lower()
        if "tmdb" in name or "movies" in name:
            return c
    return csvs[0]

def clean_dataframe(df):
    """Normalize column names and ensure required columns exist."""
    # Normalize column names (lowercase)
    df.columns = [c.strip() for c in df.columns]
    cols_lower = {c.lower(): c for c in df.columns}
    # map common variations
    def get_col(possible):
        for p in possible:
            if p in cols_lower:
                return cols_lower[p]
        return None

    title_col = get_col(['title', 'name', 'original_title'])
    lang_col = get_col(['original_language', 'language', 'lang', 'original_lang'])
    date_col = get_col(['release_date', 'date', 'release'])
    avg_col = get_col(['vote_average', 'rating', 'avg_vote', 'vote_avg'])
    count_col = get_col(['vote_count', 'votes', 'vote_cnt', 'voteCount'])

    # Build a new df with desired columns; if missing, fill with NaN/placeholder
    cleaned = pd.DataFrame()
    cleaned['title'] = df[title_col] if title_col else np.nan
    cleaned['original_language'] = df[lang_col] if lang_col else np.nan
    cleaned['release_date'] = df[date_col] if date_col else np.nan
    cleaned['vote_average'] = df[avg_col] if avg_col else np.nan
    cleaned['vote_count'] = df[count_col] if count_col else 0

    # Coerce types
    cleaned['title'] = cleaned['title'].astype(str).fillna("").str.strip()
    cleaned = cleaned[cleaned['title'] != ""]  # drop rows with empty title
    cleaned['vote_average'] = pd.to_numeric(cleaned['vote_average'], errors='coerce')
    cleaned['vote_count'] = pd.to_numeric(cleaned['vote_count'], errors='coerce').fillna(0).astype(int)
    # Parse dates
    cleaned['release_date'] = pd.to_datetime(cleaned['release_date'], errors='coerce')
    cleaned['release_year'] = cleaned['release_date'].dt.year
    # Lowercase title helper
    cleaned['title_lower'] = cleaned['title'].str.lower()
    # Good movie flag (default thresholds; you can change later)
    cleaned['good_movie'] = (cleaned['vote_average'] >= 7.0) & (cleaned['vote_count'] >= 100)
    return cleaned

def generate_sample_csv(path=OUTPUT_CSV, n=500):
    """Generate a small sample CSV with the required fields so app can be tested."""
    print("Generating sample CSV for testing...")
    sample = pd.DataFrame({
        'title': [f"Sample Movie {i}" for i in range(1, n+1)],
        'original_language': np.random.choice(['en','fr','es','hi','zh','ja','de','ko'], size=n),
        'release_date': pd.to_datetime(np.random.randint(1950, 2024, size=n), format='%Y') \
                        + pd.to_timedelta(np.random.randint(0, 365, size=n), unit='d'),
        'vote_average': np.round(np.random.uniform(2.5, 9.5, size=n), 1),
        'vote_count': np.random.randint(0, 5000, size=n)
    })
    sample['release_year'] = sample['release_date'].dt.year
    sample['title_lower'] = sample['title'].str.lower()
    sample['good_movie'] = (sample['vote_average'] >= 7.0) & (sample['vote_count'] >= 100)
    sample.to_csv(path, index=False)
    print(f"Sample CSV written to {path}")

def main():
    # Step 1: try to download
    downloaded = False
    # Only attempt kaggle if env vars present
    if os.getenv("KAGGLE_USERNAME") and os.getenv("KAGGLE_KEY"):
        downloaded = try_kaggle_download()
    else:
        print("KAGGLE_USERNAME / KAGGLE_KEY not found in env. Skipping Kaggle download attempt.")

    csv_path = find_csv_file()
    if csv_path:
        print("Found CSV:", csv_path)
        try:
            df = pd.read_csv(csv_path, low_memory=False)
            cleaned = clean_dataframe(df)
            cleaned.to_csv(OUTPUT_CSV, index=False)
            print(f"Cleaned dataset saved to {OUTPUT_CSV} (rows: {len(cleaned)})")
            return
        except Exception as e:
            print("Failed to load/clean found CSV:", e)

    # If we get here, no CSV found or cleaning failed -> generate sample
    generate_sample_csv(OUTPUT_CSV, n=500)

if __name__ == "__main__":
    main()
